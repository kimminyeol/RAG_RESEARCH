{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import TextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import math\n",
    "import torch\n",
    "\n",
    "# os.chdir('/Users/mac/AIworkspace/LLMWORKSPACE/RAG_Rec')\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raptor with rec\n",
    "1. target user의 최신 상호작용 목록을 input query로 넣음 -> 몇개 넣을지는 바꿔가며\n",
    "2. vectordb는 모든 사용자를 연결시켜둔 db에서 계층적 클러스터링을 시도함 \n",
    "3. 갑작스럽게 평점 및 영화의 장르가 변화하는 지점에서 끊어 각 상호작용의 패턴을 header로 만듦 \n",
    "4. 가장 하단 계층의 클러스터와 비교하여 유사도가 임계값을 넘는 지점 or 유사도의 변화율이 급격히 변화하는 시점에서 검색 중단 \n",
    "5. 해당되는 검색 시점의 클러스터에 있는 사용자들만을 top-100 뽑아냄 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영화기록 데이터 \n",
    "import pandas as pd\n",
    "file_path = \"data/movies.dat\"\n",
    "df2 = pd.read_csv(file_path, delimiter=\"::\", engine=\"python\", header=None,encoding=\"latin1\")\n",
    "df2.columns = [\"MovieID\", \"Title\", \"Genres\"]\n",
    "\n",
    "file_path = \"data/ratings.dat\"\n",
    "df = pd.read_csv(file_path, delimiter=\"::\", engine=\"python\", header=None,encoding=\"latin1\")\n",
    "df.columns = [\"UserId\", \"MovieID\", \"Ratings\",\"timestamp\"]\n",
    "new_df=df.merge(df2, on='MovieID')\n",
    "df_sorted = new_df.sort_values(by=['UserId', 'timestamp']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2. 사용자별 interaction 리스트 생성 ---\n",
    "df_sorted['interaction'] = df_sorted.apply(\n",
    "    lambda row: f\"{row['Genres']} (Rating: {row['Ratings']})\", axis=1\n",
    ")\n",
    "\n",
    "# 사용자별 interaction 연결 (리스트 형태)\n",
    "user_interactions = df_sorted.groupby('UserId')['interaction'].apply(list).reset_index()\n",
    "\n",
    "# 컬럼명 변경\n",
    "user_interactions.columns = ['UserId', 'interaction_list']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Step 2: 장르별 통계 저장\n",
    "def extract_genre_stats(interaction_list):\n",
    "    genre_ratings = defaultdict(list)\n",
    "\n",
    "    # 리스트 형태의 데이터 파싱\n",
    "    for entry in interaction_list:\n",
    "        genres, rating = entry.split(' (Rating: ')\n",
    "        rating = float(rating.replace(')', ''))\n",
    "        \n",
    "        for genre in genres.split('|'):\n",
    "            genre_ratings[genre].append(rating)\n",
    "\n",
    "    # 통계 생성\n",
    "    avg = {g : round(pd.Series(r).mean(),2) for g,r in genre_ratings.items()}\n",
    "    # avg_variance = {g: (round(pd.Series(r).mean(), 2), \n",
    "    #                     round(pd.Series(r).var(), 2) if len(r) > 1 else 0) \n",
    "    #                 for g, r in genre_ratings.items()}\n",
    "    \n",
    "    count = {g: len(r) for g, r in genre_ratings.items()}\n",
    "    \n",
    "    # 텍스트 생성\n",
    "    avg_var_text = ', '.join([f\"{g}({v})\" for g, v in avg.items()])\n",
    "    count_text = ', '.join([f\"{g}({v})\" for g, v in count.items()])\n",
    "    \n",
    "    return avg_var_text, count_text\n",
    "\n",
    "# Step 3: 데이터프레임 생성\n",
    "user_interactions[['avg_var_text', 'count_text']] = user_interactions['interaction_list'].apply(\n",
    "    lambda x: pd.Series(extract_genre_stats(x))\n",
    ")\n",
    "\n",
    "# 최종 결과\n",
    "user_interactions_final = user_interactions[['UserId', 'avg_var_text', 'count_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llama 활용하여 각 유저별로 header 생성 \n",
    "- 장르별 평균 평점 \n",
    "- 장르별 분산 \n",
    "- 시청횟수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlaalsduf/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "MY_HF_TOKEN = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 20:35:15.613272: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-24 20:35:15.627171: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742816115.642996 1431090 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742816115.647461 1431090 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742816115.659337 1431090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742816115.659350 1431090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742816115.659352 1431090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742816115.659353 1431090 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-24 20:35:15.663575: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3.1-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mpipeline(\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     15\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:262\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:3611\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3607\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3608\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3609\u001b[0m         )\n\u001b[1;32m   3610\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m-> 3611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   3612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3613\u001b[0m         )\n\u001b[1;32m   3615\u001b[0m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[1;32m   3616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[0;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install 'accelerate>=0.26.0'`"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>avg_var_text</th>\n",
       "      <th>count_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Drama(4.43), Comedy(4.14), Sci-Fi(4.33), Roman...</td>\n",
       "      <td>Drama(21), Comedy(14), Sci-Fi(3), Romance(6), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Action(3.5), Adventure(3.74), Romance(3.71), S...</td>\n",
       "      <td>Action(56), Adventure(19), Romance(24), Sci-Fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Drama(4.0), Thriller(3.8), Comedy(3.77), Actio...</td>\n",
       "      <td>Drama(8), Thriller(5), Comedy(30), Action(23),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId                                       avg_var_text  \\\n",
       "0       1  Drama(4.43), Comedy(4.14), Sci-Fi(4.33), Roman...   \n",
       "1       2  Action(3.5), Adventure(3.74), Romance(3.71), S...   \n",
       "2       3  Drama(4.0), Thriller(3.8), Comedy(3.77), Actio...   \n",
       "\n",
       "                                          count_text  \n",
       "0  Drama(21), Comedy(14), Sci-Fi(3), Romance(6), ...  \n",
       "1  Action(56), Adventure(19), Romance(24), Sci-Fi...  \n",
       "2  Drama(8), Thriller(5), Comedy(30), Action(23),...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=user_interactions_final.iloc[:3]\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 현재 프롬프트\n",
    "- 평점 + 시청횟수 => 둘다 높고 많으면 선호하는 장르 / 평점만 높고 횟수는 적으면 잠재 장르 \n",
    "\n",
    "##### 추가할 수 있는 부분 \n",
    "1. 다양한 장르를 골고르 => 시청횟수가 다 비슷하면 \n",
    "2. 비선호하는 장르 고르기 \n",
    "3. 분산을 통한 일관성 or 호불호 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "# Function to Generate Concise Contextual Chunk Header Using CoT\n",
    "def generate_chunk_header(avg_rating_text, count_text):\n",
    "    system_message = (\n",
    "        \"You are an expert in analyzing movie viewing behavior. \"\n",
    "        \"Your task is to analyze the user's movie preferences and generate a concise summary of their overall viewing pattern. \"\n",
    "        \"Do NOT include specific rating numbers, viewing counts, or detailed explanations. \"\n",
    "        \"Only provide a brief and meaningful summary of their primary preferences and emerging interests. \"\n",
    "        \"Your final response should be 1-2 clear and natural sentences.\"\n",
    "    )\n",
    "\n",
    "    user_message = f\"\"\"\n",
    "### INPUT DATA ###\n",
    "1. **Genre Statistics (Average Rating):** {avg_rating_text}\n",
    "2. **Genre Viewing Frequency (Count):** {count_text}\n",
    "\n",
    "### OUTPUT FORMAT EXAMPLE ###\n",
    "\"This user enjoys emotional and family-oriented genres while occasionally exploring niche genres like Sci-Fi.\"\n",
    "\n",
    "### RESPONSE ###\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ]\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=512,\n",
    "        eos_token_id=terminators,\n",
    "        pad_token_id = terminators[0],\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9\n",
    "    )\n",
    "\n",
    "    return outputs[0]['generated_text'][2]['content']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x\u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_chunk_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg_var_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 32\u001b[0m, in \u001b[0;36mgenerate_chunk_header\u001b[0;34m(avg_rating_text, count_text)\u001b[0m\n\u001b[1;32m     14\u001b[0m     user_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m### INPUT DATA ###\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m1. **Genre Statistics (Average Rating):** \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_rating_text\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124m### RESPONSE ###\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     26\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     27\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_message},\n\u001b[1;32m     28\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_message},\n\u001b[1;32m     29\u001b[0m     ]\n\u001b[1;32m     31\u001b[0m     terminators \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 32\u001b[0m         \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[1;32m     33\u001b[0m         pipeline\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|eot_id|>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m     ]\n\u001b[1;32m     36\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m     37\u001b[0m         messages,\n\u001b[1;32m     38\u001b[0m         max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m         top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'tokenizer'"
     ]
    }
   ],
   "source": [
    "x= generate_chunk_header(k['avg_var_text'].iloc[0] , k['count_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_chunk_header' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m user_interactions_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunk_header\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43muser_interactions_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_chunk_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg_var_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m user_interactions_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunk_header\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m user_interactions_final\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mgenerate_chunk_header\u001b[49m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_var_text\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount_text\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_chunk_header' is not defined"
     ]
    }
   ],
   "source": [
    "user_interactions_final['chunk_header'] = user_interactions_final.apply(lambda row: generate_chunk_header(row['avg_var_text'], row['count_text']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('header_vanila.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 생성된 header를 활용하여 raptor에 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 임베딩 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 22:37:01.922142: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-24 22:37:01.938033: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742823421.956543 1438256 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742823421.962029 1438256 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742823421.976656 1438256 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742823421.976670 1438256 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742823421.976671 1438256 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742823421.976673 1438256 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-24 22:37:01.981754: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리들 임포트 미리 준비\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# 만들어진 청크를 임베딩하는 클래스\n",
    "class EmbeddingGenerator:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = SentenceTransformer(model_name, device= device)\n",
    "    \n",
    "    def embed_texts(self, texts: list[str]) -> np.ndarray:\n",
    "        # 텍스트 리스트를 임베딩 벡터로 변환하여 반환\n",
    "        return self.model.encode(texts, convert_to_numpy=True, device='cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- raptor 기반 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMMClusterer:\n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit_predict(self, embeddings: np.ndarray, n_clusters: int) -> np.ndarray:\n",
    "        # 🔥 매 레벨마다 n_clusters를 전달하도록 변경\n",
    "        gmm = GaussianMixture(n_components=n_clusters, random_state=self.random_state)\n",
    "        return gmm.fit_predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaptorTree:\n",
    "    def __init__(self, embedding_generator, clusterer, min_clusters=2, max_level=5, top_level_clusters=100):\n",
    "        self.embedding_generator = embedding_generator\n",
    "        self.clusterer = clusterer\n",
    "        self.min_clusters = min_clusters\n",
    "        self.max_level = max_level\n",
    "        self.top_level_clusters = top_level_clusters\n",
    "        self.tree = {}\n",
    "        self.user_id_to_text = {}\n",
    "\n",
    "    def build_tree(self, texts: list[str], user_ids: list[str]):\n",
    "        self.user_id_to_text = dict(zip(user_ids, texts))\n",
    "        current_texts = texts\n",
    "        current_user_ids = user_ids\n",
    "        current_level = 0\n",
    "        parent_ids = None\n",
    "\n",
    "        while len(current_texts) > 1 and current_level < self.max_level:\n",
    "            embeddings = self.embedding_generator.embed_texts(current_texts)\n",
    "\n",
    "            # 🔥 클러스터 개수 설정 수정 (빈 클러스터 방지)\n",
    "            n_clusters = max(self.min_clusters, min(len(current_texts) // 2, self.top_level_clusters // (current_level + 1)))\n",
    "\n",
    "            cluster_labels = self.clusterer.fit_predict(embeddings, n_clusters=n_clusters)\n",
    "\n",
    "            cluster_metadata = []\n",
    "            next_level_texts = []\n",
    "            next_level_user_ids = []\n",
    "\n",
    "            for cluster_id in np.unique(cluster_labels):\n",
    "                cluster_indices = np.where(cluster_labels == cluster_id)[0]\n",
    "                cluster_texts = [current_texts[i] for i in cluster_indices]\n",
    "\n",
    "                # 🔥 빈 클러스터 제거\n",
    "                if len(cluster_texts) == 0:\n",
    "                    continue\n",
    "\n",
    "                # 🔥 첫 번째 레벨에서는 user_ids 그대로 사용\n",
    "                if current_level == 0:\n",
    "                    cluster_user_ids = [current_user_ids[i] for i in cluster_indices]\n",
    "                else:\n",
    "                    # 상위 레벨에서는 이전 클러스터 ID 기준으로 `user_ids` 추가\n",
    "                    cluster_user_ids = []\n",
    "                    for idx in cluster_indices:\n",
    "                        child_cluster_id = current_user_ids[idx]\n",
    "                        for child_meta in self.tree[current_level - 1]:\n",
    "                            if child_meta[\"cluster_id\"] == child_cluster_id:\n",
    "                                cluster_user_ids.extend(child_meta[\"user_ids\"])\n",
    "\n",
    "                # 🔥 대표 텍스트 (가장 긴 텍스트 선정)\n",
    "                representative_text = max(cluster_texts, key=len)\n",
    "\n",
    "                cluster_embeddings = embeddings[cluster_indices]\n",
    "                mean_embedding = cluster_embeddings.mean(axis=0)\n",
    "\n",
    "                # 🔥 올바른 parent_id 설정 (부모 클러스터 1개만 추가)\n",
    "                metadata = {\n",
    "                    \"cluster_id\": f\"level_{current_level}_cluster_{cluster_id}\",\n",
    "                    \"level\": current_level,\n",
    "                    \"user_ids\": cluster_user_ids,  # ✅ 첫 번째 레벨에서도 user_ids 추가\n",
    "                    \"embedding\": mean_embedding,\n",
    "                    \"parent_id\": parent_ids if parent_ids else [],\n",
    "                    \"child_ids\": None\n",
    "                }\n",
    "\n",
    "                cluster_metadata.append(metadata)\n",
    "                next_level_texts.append(representative_text)\n",
    "                next_level_user_ids.append(metadata[\"cluster_id\"])\n",
    "\n",
    "            # 클러스터 메타데이터 추가\n",
    "            self.tree[current_level] = cluster_metadata\n",
    "            current_texts = next_level_texts\n",
    "            current_user_ids = next_level_user_ids\n",
    "            parent_ids = current_user_ids\n",
    "            current_level += 1\n",
    "\n",
    "        return self.tree\n",
    "\n",
    "    def search_user_cluster(self, target_user_id: str, target_user_text: str, threshold=0.01):\n",
    "        query_embedding = self.embedding_generator.embed_texts([target_user_text])[0]\n",
    "        current_level = max(self.tree.keys())\n",
    "        previous_similarity = None\n",
    "        best_cluster = None\n",
    "\n",
    "        while current_level >= 0:\n",
    "            clusters = self.tree[current_level]\n",
    "            clusters_filtered = []\n",
    "            clusters_filtered_embeddings = []\n",
    "\n",
    "            for cluster in clusters:\n",
    "                cluster_user_ids = cluster[\"user_ids\"]\n",
    "\n",
    "                # 🔥 클러스터 ID가 아닌 실제 유저 ID만 필터링\n",
    "                texts_to_embed = [\n",
    "                    self.user_id_to_text[uid] for uid in cluster_user_ids\n",
    "                    if uid != target_user_id and 'cluster' not in uid\n",
    "                ]\n",
    "                if not texts_to_embed:\n",
    "                    continue\n",
    "\n",
    "                embeddings_cluster = self.embedding_generator.embed_texts(texts_to_embed)\n",
    "                mean_embedding = embeddings_cluster.mean(axis=0)\n",
    "\n",
    "                clusters_filtered.append(cluster)\n",
    "                clusters_filtered_embeddings.append(mean_embedding)\n",
    "\n",
    "            if not clusters_filtered:\n",
    "                break\n",
    "\n",
    "            similarities = cosine_similarity([query_embedding], clusters_filtered_embeddings).flatten()\n",
    "            best_idx = np.argmax(similarities)\n",
    "            best_cluster = clusters_filtered[best_idx]\n",
    "            current_similarity = similarities[best_idx]\n",
    "\n",
    "            if previous_similarity and abs(previous_similarity - current_similarity) / previous_similarity > threshold:\n",
    "                break\n",
    "\n",
    "            previous_similarity = current_similarity\n",
    "            current_level -= 1\n",
    "\n",
    "        best_cluster_users_excluded = [uid for uid in best_cluster[\"user_ids\"] if uid != target_user_id]\n",
    "        return best_cluster[\"cluster_id\"], best_cluster_users_excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 클러스터 수를 늘리며 변화율의 증폭기간에서 멈춤 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유저 2가 가장 유사한 클러스터: level_2_cluster_16\n",
      "해당 클러스터에 속한 유사 유저 목록 (본인 제외): ['46', '127', '304', '1089', '1302', '1424', '1610', '1726', '1927', '2101', '2126', '2146', '2263', '2297', '2363', '2441', '2514', '3144', '3352', '3460', '3567', '3636', '3673', '4000', '4031', '4109', '4160', '4587', '4690', '4874', '4892', '5040', '5069', '5469', '5703', '5895', '6034', '7', '277', '296', '431', '908', '1030', '1131', '1200', '1398', '1520', '1649', '1866', '2466', '2598', '2663', '3048', '3068', '3307', '3337', '3459', '3461', '3487', '3662', '3818', '3978', '4093', '4183', '4417', '4489', '4499', '4626', '5003', '5029', '5095', '5854', '5870', '5871', '5884', '5912', '5947', '6020', '185', '279', '422', '542', '633', '677', '700', '917', '1260', '1269', '1533', '1548', '1567', '1682', '2062', '2114', '2163', '2211', '2357', '2369', '2388', '2479', '2625', '2642', '2767', '2967', '3027', '3162', '3187', '3455', '3490', '3616', '3733', '3822', '3828', '3855', '4200', '4207', '4531', '4579', '5309', '5389', '5737', '5749', '5859']\n"
     ]
    }
   ],
   "source": [
    "# 초기화 예시\n",
    "embedding_gen = EmbeddingGenerator()\n",
    "clusterer = GMMClusterer()\n",
    "\n",
    "# 초기 RAPTOR 트리 생성 (한 번만 수행)\n",
    "# 클래스 초기화 부분\n",
    "raptor_tree = RaptorTree(\n",
    "    embedding_gen, \n",
    "    clusterer,\n",
    "    min_clusters=2,\n",
    "    max_level=5,          # 더 높이거나 낮춰서 조정\n",
    "    top_level_clusters=100 # 최상위 클러스터 수를 늘리거나 줄여본다\n",
    ")\n",
    "tree_structure = raptor_tree.build_tree(df.chunk_header.tolist(), df.UserId.astype(str).tolist())\n",
    "\n",
    "# 특정 사용자 검색 수행 (Self-exclusion 방식 적용)\n",
    "target_user_id = \"2\"\n",
    "target_user_text = df.loc[df.UserId == int(target_user_id), 'chunk_header'].iloc[0]\n",
    "\n",
    "best_cluster_id, similar_users = raptor_tree.search_user_cluster(\n",
    "    target_user_id, target_user_text, threshold=0.005\n",
    ")\n",
    "\n",
    "print(f\"유저 {target_user_id}가 가장 유사한 클러스터: {best_cluster_id}\")\n",
    "print(f\"해당 클러스터에 속한 유사 유저 목록 (본인 제외): {similar_users}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1차 필터링 완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similar_users) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. meta chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최소 조건 없는 청킹 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1438256/321042087.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.load_local(\n",
    "    \"vectorstore_index_ratings_min5_no\",\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True  # 역직렬화 허용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['1917 (Action|Adventure|Sci-Fi|Thriller) ratings: 3']\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "file_path='data/train_movie.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "# 'movie_explain' 열을 리스트로 변환\n",
    "data['movie_explain'] = data['movie_explain'].apply(ast.literal_eval)\n",
    "file_path_test='data/test_movie.csv'\n",
    "# 최신 구매 기록을 가져옴\n",
    "purchase_history=data.iloc[1]['movie_explain']\n",
    "# 정답 데이터셋 가져옴\n",
    "df_test=pd.read_csv(file_path_test)\n",
    "# 정답\n",
    "df_test.iloc[1].movie_explain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1438256/3104281221.py:16: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  records = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "# 🔹 최신 구매 기록 (Query)\n",
    "query = \" \".join(purchase_history[-1:])  # 리스트를 문자열로 변환\n",
    "\n",
    "# 🔹 similar_users의 타입 확인 후 변환\n",
    "similar_users_str = set(map(str, similar_users))  # 문자열 변환\n",
    "\n",
    "# 🔹 FAISS에서 `similar_users`만 검색하도록 필터 추가\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 500,\n",
    "        # \"filter\": user_filter  # 🔥 수정된 부분\n",
    "    }\n",
    ")\n",
    "\n",
    "# 🔹 검색 수행\n",
    "records = retriever.get_relevant_documents(query)\n",
    "\n",
    "# 🔹 결과 확인\n",
    "record_user_ids = [str(record.metadata['UserId']) for record in records]\n",
    "intersection = similar_users_str.intersection(set(record_user_ids))\n",
    "\n",
    "# 🔹 'similar_users'에 속하는 유저만 필터링\n",
    "filtered_records = [\n",
    "    record for record in records \n",
    "    if str(record.metadata['UserId']) in similar_users_str\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "def get_documents_with_context(\n",
    "    vectorstore: FAISS,\n",
    "    filtered_records: List[Document],\n",
    "    context_window: int = 1\n",
    ") -> List[List[Document]]:\n",
    "    \"\"\"\n",
    "    intersection 유저들의 검색 결과와 각 결과의 앞뒤 문서들을 함께 반환합니다.\n",
    "    \n",
    "    Args:\n",
    "        vectorstore: FAISS 벡터스토어 인스턴스\n",
    "        filtered_records: 검색된 유저들의 기록\n",
    "        context_window: 앞뒤로 가져올 문서 수 (default: 1)\n",
    "    \n",
    "    Returns:\n",
    "        List[List[Document]]: 각 검색 결과에 대해 [이전 문서들, 현재 문서, 다음 문서들]을 포함하는 리스트\n",
    "    \"\"\"\n",
    "    \n",
    "    # 🔹 모든 문서와 메타데이터를 딕셔너리로 구성\n",
    "    all_docs = {}\n",
    "    for doc_id, doc in enumerate(vectorstore.docstore._dict.values()):\n",
    "        user_id = str(doc.metadata['UserId'])\n",
    "        chunk_idx = doc.metadata['chunk_index']\n",
    "        \n",
    "        if user_id not in all_docs:\n",
    "            all_docs[user_id] = {}\n",
    "        all_docs[user_id][chunk_idx] = doc\n",
    "    \n",
    "    # 🔹 Context 추가\n",
    "    context_results = []\n",
    "    \n",
    "    for doc in filtered_records:\n",
    "        current_user_id = str(doc.metadata['UserId'])\n",
    "        current_chunk_index = doc.metadata['chunk_index']\n",
    "        \n",
    "        context_docs = []\n",
    "        \n",
    "        # 🔹 이전 문서들 추가\n",
    "        for i in range(current_chunk_index - context_window, current_chunk_index):\n",
    "            if current_user_id in all_docs and i in all_docs[current_user_id]:\n",
    "                context_docs.append(all_docs[current_user_id][i])\n",
    "        \n",
    "        # 🔹 현재 문서 추가\n",
    "        context_docs.append(doc)\n",
    "        \n",
    "        # 🔹 다음 문서들 추가\n",
    "        for i in range(current_chunk_index + 1, current_chunk_index + context_window + 1):\n",
    "            if current_user_id in all_docs and i in all_docs[current_user_id]:\n",
    "                context_docs.append(all_docs[current_user_id][i])\n",
    "        \n",
    "        context_results.append(context_docs)\n",
    "    \n",
    "    return context_results\n",
    "\n",
    "# 🔹 intersection 유저들의 청크 앞뒤 청크 추출\n",
    "context_results = get_documents_with_context(vectorstore, filtered_records, context_window=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"3020 (Action|Drama) ratings: 5 292 (Action|Drama|Thriller) ratings: 3 1769 (Action|Thriller) ratings: 2 736 (Action|Adventure|Romance|Thriller) ratings: 2 1667 (Action|Drama) ratings: 4 434 (Action|Adventure|Crime) ratings: 3 511 (Action|Drama) ratings: 3 2126 (Action|Crime|Mystery|Thriller) ratings: 3 2094 (Action|Adventure|Sci-Fi) ratings: 3\\n1544 (Action|Adventure|Sci-Fi|Thriller) ratings: 1 420 (Action|Comedy) ratings: 3 208 (Action|Adventure) ratings: 1 2409 (Action|Drama) ratings: 5 2410 (Action|Drama) ratings: 2\\n2411 (Action|Drama) ratings: 5 2412 (Action|Drama) ratings: 2 1954 (Action|Drama) ratings: 5 2657 (Comedy|Horror|Musical|Sci-Fi) ratings: 2 2628 (Action|Adventure|Fantasy|Sci-Fi) ratings: 4\\n1320 (Action|Horror|Sci-Fi|Thriller) ratings: 5 674 (Adventure|Sci-Fi) ratings: 4 2311 (Mystery|Sci-Fi) ratings: 4 1690 (Action|Horror|Sci-Fi) ratings: 4 2641 (Action|Adventure|Sci-Fi) ratings: 2 3300 (Action|Sci-Fi) ratings: 3 3033 (Comedy|Sci-Fi) ratings: 2 2094 (Action|Adventure|Sci-Fi) ratings: 3 788 (Comedy|Fantasy|Romance|Sci-Fi) ratings: 2 329 (Action|Adventure|Sci-Fi) ratings: 1\\n1544 (Action|Adventure|Sci-Fi|Thriller) ratings: 3 1917 (Action|Adventure|Sci-Fi|Thriller) ratings: 3 196 (Horror|Sci-Fi) ratings: 3 1779 (Adventure|Sci-Fi|Thriller) ratings: 3 173 (Action|Adventure|Sci-Fi) ratings: 2 3354 (Sci-Fi) ratings: 3 2851 (Adventure|Sci-Fi|Thriller) ratings: 3 880 (Sci-Fi|Thriller) ratings: 3\\n160 (Action|Adventure|Mystery|Sci-Fi) ratings: 1 2448 (Horror|Sci-Fi) ratings: 2 1862 (Horror|Sci-Fi) ratings: 3 1129 (Action|Adventure|Sci-Fi|Thriller) ratings: 3 1374 (Action|Adventure|Sci-Fi) ratings: 2 2287 (Sci-Fi|Thriller|War) ratings: 3 1356 (Action|Adventure|Sci-Fi) ratings: 2 748 (Action|Sci-Fi|Thriller) ratings: 3 1240 (Action|Sci-Fi|Thriller) ratings: 4 1200 (Action|Sci-Fi|Thriller|War) ratings: 5\\n1603 (Sci-Fi|Thriller) ratings: 3 2628 (Action|Adventure|Fantasy|Sci-Fi) ratings: 1 1320 (Action|Horror|Sci-Fi|Thriller) ratings: 4 1371 (Action|Adventure|Sci-Fi) ratings: 3 788 (Comedy|Fantasy|Romance|Sci-Fi) ratings: 1\\n1544 (Action|Adventure|Sci-Fi|Thriller) ratings: 3 3354 (Sci-Fi) ratings: 3 748 (Action|Sci-Fi|Thriller) ratings: 4 780 (Action|Sci-Fi|War) ratings: 4 2808 (Action|Sci-Fi) ratings: 2\\n3024 (Horror|Sci-Fi) ratings: 4 1917 (Action|Adventure|Sci-Fi|Thriller) ratings: 3 1779 (Adventure|Sci-Fi|Thriller) ratings: 3 172 (Action|Sci-Fi|Thriller) ratings: 1 849 (Action|Adventure|Sci-Fi|Thriller) ratings: 2 880 (Sci-Fi|Thriller) ratings: 2 173 (Action|Adventure|Sci-Fi) ratings: 1\\n1376 (Action|Adventure|Sci-Fi) ratings: 2 3740 (Action|Comedy) ratings: 3 555 (Action|Crime|Romance) ratings: 4 1676 (Action|Adventure|Sci-Fi|War) ratings: 4 480 (Action|Adventure|Sci-Fi) ratings: 2 1527 (Action|Sci-Fi) ratings: 1\\n1573 (Action|Sci-Fi|Thriller) ratings: 5 1580 (Action|Adventure|Comedy|Sci-Fi) ratings: 1 1587 (Action|Adventure) ratings: 3 163 (Action|Romance|Thriller) ratings: 5 2989 (Action) ratings: 2\\n2058 (Action|Thriller) ratings: 4 3444 (Action) ratings: 1 2826 (Action|Horror|Thriller) ratings: 3 1377 (Action|Adventure|Comedy|Crime) ratings: 2 3519 (Action|War) ratings: 3\\n1270 (Comedy|Sci-Fi) ratings: 3 1097 (Children's|Drama|Fantasy|Sci-Fi) ratings: 2 480 (Action|Adventure|Sci-Fi) ratings: 3 920 (Drama|Romance|War) ratings: 5 1589 (Crime|Drama|Mystery) ratings: 4\\n1573 (Action|Sci-Fi|Thriller) ratings: 4 2916 (Action|Adventure|Sci-Fi|Thriller) ratings: 3 1580 (Action|Adventure|Comedy|Sci-Fi) ratings: 4 1748 (Film-Noir|Sci-Fi|Thriller) ratings: 4 329 (Action|Adventure|Sci-Fi) ratings: 2 788 (Comedy|Fantasy|Romance|Sci-Fi) ratings: 2 2628 (Action|Adventure|Fantasy|Sci-Fi) ratings: 2 2827 (Sci-Fi|Thriller) ratings: 3\\n1219 (Horror|Thriller) ratings: 5 593 (Drama|Thriller) ratings: 5 1617 (Crime|Film-Noir|Mystery|Thriller) ratings: 3 608 (Crime|Drama|Thriller) ratings: 5 50 (Crime|Thriller) ratings: 5 3147 (Drama|Thriller) ratings: 4 2762 (Thriller) ratings: 5\\n628 (Drama|Thriller) ratings: 5 802 (Drama|Romance) ratings: 5 1748 (Film-Noir|Sci-Fi|Thriller) ratings: 3 2353 (Action|Thriller) ratings: 5 1061 (Crime|Drama) ratings: 4 3252 (Drama) ratings: 4 21 (Action|Comedy|Drama) ratings: 4 454 (Drama|Thriller) ratings: 4 3108 (Comedy|Drama|Romance) ratings: 3\\n1573 (Action|Sci-Fi|Thriller) ratings: 5 1754 (Action|Mystery|Thriller) ratings: 5 832 (Drama|Thriller) ratings: 4 3793 (Action|Sci-Fi) ratings: 3 3578 (Action|Drama) ratings: 4\\n1997 (Horror) ratings: 3 3617 (Comedy) ratings: 3 3863 (Sci-Fi|Thriller) ratings: 4 3755 (Action|Adventure|Thriller) ratings: 3 3826 (Horror|Sci-Fi|Thriller) ratings: 3 3717 (Action|Crime) ratings: 3\\n2394 (Animation|Musical) ratings: 3 69 (Comedy) ratings: 4 509 (Drama|Romance) ratings: 2 999 (Crime) ratings: 2 543 (Comedy|Romance|Thriller) ratings: 1\\n1527 (Action|Sci-Fi) ratings: 4 353 (Action|Romance|Thriller) ratings: 2 10 (Action|Adventure|Thriller) ratings: 2 2676 (Drama|Thriller) ratings: 4 991 (Drama|War) ratings: 4 1589 (Crime|Drama|Mystery) ratings: 3\\n371 (Comedy|Drama) ratings: 5 2439 (Drama) ratings: 3 1799 (Crime|Drama) ratings: 4 2427 (Action|Drama|War) ratings: 5 802 (Drama|Romance) ratings: 1\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "flattened_results = [doc for sublist in context_results for doc in sublist]\n",
    "record_summary = \"\\n\".join([doc.page_content for doc in flattened_results])\n",
    "record_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie 788: watched by 3 users\n",
      "Movie 1573: watched by 3 users\n",
      "Movie 2094: watched by 2 users\n",
      "Movie 1320: watched by 2 users\n",
      "Movie 329: watched by 2 users\n",
      "Movie 1917: watched by 2 users\n",
      "Movie 1779: watched by 2 users\n",
      "Movie 173: watched by 2 users\n",
      "Movie 3354: watched by 2 users\n",
      "Movie 880: watched by 2 users\n",
      "Movie 748: watched by 2 users\n",
      "Movie 1580: watched by 2 users\n",
      "Movie 1589: watched by 2 users\n",
      "Movie 1748: watched by 2 users\n",
      "Movie 802: watched by 2 users\n",
      "Movie 3020: watched by 1 users\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def get_user_movies(data):\n",
    "    user_movies = defaultdict(list)\n",
    "\n",
    "    for doc in data:\n",
    "        user_id = doc.metadata['UserId']\n",
    "        page_content = doc.page_content\n",
    "\n",
    "        # 정규식을 사용하여 영화 ID 추출 (ratings 이전 내용만)\n",
    "        movie_ids = re.findall(r'(\\d+)(?= \\()', page_content)\n",
    "\n",
    "        # 사용자별로 영화 ID 추가\n",
    "        user_movies[user_id].extend(movie_ids)\n",
    "\n",
    "    return user_movies\n",
    "\n",
    "def create_user_movie_graph(user_movies):\n",
    "    # 그래프 생성\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # 사용자와 영화 노드 추가 및 엣지 생성\n",
    "    for user_id, movies in user_movies.items():\n",
    "        user_node = f\"User {user_id}\"\n",
    "        G.add_node(user_node, type='user')\n",
    "\n",
    "        for movie_id in movies:\n",
    "            movie_node = f\"Movie {movie_id}\"\n",
    "            G.add_node(movie_node, type='movie')\n",
    "            G.add_edge(user_node, movie_node)\n",
    "\n",
    "    return G\n",
    "\n",
    "def visualize_graph(G):\n",
    "    # 그래프 시각화\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # 사용자와 영화 노드 분리\n",
    "    users = [node for node in G.nodes() if G.nodes[node]['type'] == 'user']\n",
    "    movies = [node for node in G.nodes() if G.nodes[node]['type'] == 'movie']\n",
    "\n",
    "    # 레이아웃 설정\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=50)\n",
    "\n",
    "    # 노드 그리기\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=users, node_color='lightblue', node_size=300, alpha=0.8)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=movies, node_color='lightgreen', node_size=200, alpha=0.8)\n",
    "\n",
    "    # 엣지 그리기\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "\n",
    "    # 레이블 그리기\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8, font_weight=\"bold\")\n",
    "\n",
    "    plt.title(\"User-Movie Relationship Graph\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 그래프 저장\n",
    "    plt.savefig('user_movie_graph.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "import re\n",
    "\n",
    "# 과거 기록에서 영화 ID 추출\n",
    "def extract_previous_movie_ids(purchase_history):\n",
    "    # 영화 ID만 추출 (숫자와 괄호 전까지만 가져옴)\n",
    "    previous_movies = re.findall(r'(\\d+)(?=\\s\\()', ' '.join(purchase_history))\n",
    "    return set(previous_movies)\n",
    "\n",
    "# 동시 시청 영화에서 이전 기록을 제외하는 함수\n",
    "def filter_movies_by_history(top_movies, previous_movie_ids):\n",
    "    # 영화 ID만 추출하여 비교 후 제외\n",
    "    filtered_movies = [(movie, count) for movie, count in top_movies if movie.split()[1] not in previous_movie_ids]\n",
    "    return filtered_movies\n",
    "def get_top_10_common_movies(G):\n",
    "    # 영화 노드만 필터링\n",
    "    movies = [node for node in G.nodes() if G.nodes[node]['type'] == 'movie']\n",
    "\n",
    "    # 영화별 연결된 사용자 수 계산\n",
    "    movie_view_counts = {movie: len(list(G.neighbors(movie))) for movie in movies}\n",
    "\n",
    "    # 사용자 수 기준으로 내림차순 정렬하여 상위 10개 추출\n",
    "    top_10_movies = sorted(movie_view_counts.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "    # 결과 반환\n",
    "    return top_10_movies\n",
    "\n",
    "# 사용자별 영화 ID 가져오기\n",
    "user_movies = get_user_movies(flattened_results)\n",
    "\n",
    "# 사용자-영화 그래프 생성\n",
    "G = create_user_movie_graph(user_movies)\n",
    "\n",
    "previous_movie_ids = extract_previous_movie_ids(purchase_history)\n",
    "\n",
    "# Top-10 영화 리스트 가져오기\n",
    "top_movies = get_top_10_common_movies(G)\n",
    "\n",
    "# 이전 기록에 포함되지 않은 영화만 필터링\n",
    "filtered_movies = filter_movies_by_history(top_movies, previous_movie_ids)\n",
    "\n",
    "# 결과 출력\n",
    "for movie, count in filtered_movies:\n",
    "    print(f\"{movie}: watched by {count} users\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['1917 (Action|Adventure|Sci-Fi|Thriller) ratings: 3']\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.iloc[1].movie_explain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- raptor로 1차 검색 유저 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 특정 사용자 검색 수행 (Self-exclusion 방식 적용)\n",
    "target_user_id = \"2\"\n",
    "target_user_text = df.loc[df.UserId == int(target_user_id), 'chunk_header'].iloc[0]\n",
    "\n",
    "best_cluster_id, similar_users = raptor_tree.search_user_cluster(\n",
    "    target_user_id, target_user_text, threshold=0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최신 구매 기록을 가져옴\n",
    "purchase_history=data.iloc[1]['movie_explain']\n",
    "# 정답\n",
    "answer= df_test.iloc[1].movie_explain\n",
    "# 🔹 최신 구매 기록 (Query)\n",
    "query = \" \".join(purchase_history[-1:])  # 리스트를 문자열로 변환\n",
    "# 🔹 similar_users의 타입 확인 후 변환\n",
    "similar_users_str = set(map(str, similar_users))  # 문자열 변환\n",
    "# 🔹 FAISS에서 `similar_users`만 검색하도록 필터 추가\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 500,\n",
    "    }\n",
    ")\n",
    "# 🔹 검색 수행\n",
    "records = retriever.get_relevant_documents(query)\n",
    "\n",
    "# 🔹 결과 확인\n",
    "record_user_ids = [str(record.metadata['UserId']) for record in records]\n",
    "intersection = similar_users_str.intersection(set(record_user_ids))\n",
    "\n",
    "# 🔹 'similar_users'에 속하는 유저만 필터링\n",
    "filtered_records = [\n",
    "    record for record in records \n",
    "    if str(record.metadata['UserId']) in similar_users_str\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie 788: watched by 3 users\n",
      "Movie 1573: watched by 3 users\n",
      "Movie 2094: watched by 2 users\n",
      "Movie 1320: watched by 2 users\n",
      "Movie 329: watched by 2 users\n",
      "Movie 1917: watched by 2 users\n",
      "Movie 1779: watched by 2 users\n",
      "Movie 173: watched by 2 users\n",
      "Movie 3354: watched by 2 users\n",
      "Movie 880: watched by 2 users\n",
      "Movie 748: watched by 2 users\n",
      "Movie 1580: watched by 2 users\n",
      "Movie 1589: watched by 2 users\n",
      "Movie 1748: watched by 2 users\n",
      "Movie 802: watched by 2 users\n",
      "Movie 3020: watched by 1 users\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 🔹 intersection 유저들의 청크 앞뒤 청크 추출\n",
    "context_results = get_documents_with_context(vectorstore, filtered_records, context_window=1)\n",
    "\n",
    "flattened_results = [doc for sublist in context_results for doc in sublist]\n",
    "# 사용자별 영화 ID 가져오기\n",
    "user_movies = get_user_movies(flattened_results)\n",
    "\n",
    "# 사용자-영화 그래프 생성\n",
    "G = create_user_movie_graph(user_movies)\n",
    "\n",
    "previous_movie_ids = extract_previous_movie_ids(purchase_history)\n",
    "\n",
    "# Top-10 영화 리스트 가져오기\n",
    "top_movies = get_top_10_common_movies(G)\n",
    "\n",
    "# 이전 기록에 포함되지 않은 영화만 필터링\n",
    "filtered_movies = filter_movies_by_history(top_movies, previous_movie_ids)\n",
    "\n",
    "# 결과 출력\n",
    "for movie, count in filtered_movies:\n",
    "    print(f\"{movie}: watched by {count} users\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 정답을 맞췄습니다!\n"
     ]
    }
   ],
   "source": [
    "# 추천 영화 리스트에서 영화 ID만 추출\n",
    "filtered_movie_ids = [re.search(r\"(\\d+)\", movie).group(1) for movie, _ in filtered_movies]\n",
    "answer_id = re.search(r\"(\\d+)\", answer).group(1)\n",
    "# 정답 검증\n",
    "if answer_id in filtered_movie_ids:\n",
    "    print(\"🎯 정답을 맞췄습니다!\")\n",
    "else:\n",
    "    print(\"❌ 정답을 맞추지 못했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m target_user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 유저 ID는 1부터 시작\u001b[39;00m\n\u001b[1;32m     10\u001b[0m target_user_text \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df\u001b[38;5;241m.\u001b[39mUserId \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mint\u001b[39m(target_user_id), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunk_header\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m best_cluster_id, similar_users \u001b[38;5;241m=\u001b[39m \u001b[43mraptor_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_user_cluster\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_user_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_user_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.005\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 최신 구매 기록\u001b[39;00m\n\u001b[1;32m     17\u001b[0m purchase_history \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_explain\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[7], line 101\u001b[0m, in \u001b[0;36mRaptorTree.search_user_cluster\u001b[0;34m(self, target_user_id, target_user_text, threshold)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m texts_to_embed:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m embeddings_cluster \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts_to_embed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m mean_embedding \u001b[38;5;241m=\u001b[39m embeddings_cluster\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    104\u001b[0m clusters_filtered\u001b[38;5;241m.\u001b[39mappend(cluster)\n",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m, in \u001b[0;36mEmbeddingGenerator.embed_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membed_texts\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# 텍스트 리스트를 임베딩 벡터로 변환하여 반환\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:586\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    585\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 586\u001b[0m length_sorted_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort([\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_length(sen) \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sentences])\n\u001b[1;32m    587\u001b[0m sentences_sorted \u001b[38;5;241m=\u001b[39m [sentences[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m length_sorted_idx]\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:586\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    585\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 586\u001b[0m length_sorted_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort([\u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_text_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43msen\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sentences])\n\u001b[1;32m    587\u001b[0m sentences_sorted \u001b[38;5;241m=\u001b[39m [sentences[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m length_sorted_idx]\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:1478\u001b[0m, in \u001b[0;36mSentenceTransformer._text_length\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text)\n\u001b[1;32m   1477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28mlen\u001b[39m(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m text])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:1478\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text)\n\u001b[1;32m   1477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m text])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 결과 저장을 위한 빈 DataFrame 생성\n",
    "results = pd.DataFrame(columns=[\"UserId\", \"Hit\", \"Answer\", \"Recommended\"])\n",
    "\n",
    "# 전체 유저 반복 및 기록\n",
    "for idx in range(100):\n",
    "    target_user_id = str(idx + 1)  # 유저 ID는 1부터 시작\n",
    "    target_user_text = df.loc[df.UserId == int(target_user_id), 'chunk_header'].iloc[0]\n",
    "\n",
    "    best_cluster_id, similar_users = raptor_tree.search_user_cluster(\n",
    "        target_user_id, target_user_text, threshold=0.005\n",
    "    )\n",
    "\n",
    "    # 최신 구매 기록\n",
    "    purchase_history = data.iloc[idx]['movie_explain']\n",
    "    query = \" \".join(purchase_history[-1:])\n",
    "\n",
    "    # 검색 수행\n",
    "    records = retriever.get_relevant_documents(query)\n",
    "    record_user_ids = [str(record.metadata['UserId']) for record in records]\n",
    "    intersection = set(map(str, similar_users)).intersection(set(record_user_ids))\n",
    "\n",
    "    # 'similar_users'에 속하는 유저만 필터링\n",
    "    filtered_records = [\n",
    "        record for record in records\n",
    "        if str(record.metadata['UserId']) in intersection\n",
    "    ]\n",
    "\n",
    "    # Intersection 유저들의 청크 앞뒤 청크 추출\n",
    "    context_results = get_documents_with_context(vectorstore, filtered_records, context_window=1)\n",
    "    flattened_results = [doc for sublist in context_results for doc in sublist]\n",
    "\n",
    "    # 사용자별 영화 ID 가져오기\n",
    "    user_movies = get_user_movies(flattened_results)\n",
    "\n",
    "    # 사용자-영화 그래프 생성\n",
    "    G = create_user_movie_graph(user_movies)\n",
    "\n",
    "    # Top-10 영화 리스트 가져오기\n",
    "    top_movies = get_top_10_common_movies(G)\n",
    "\n",
    "    # 이전 기록에 포함되지 않은 영화만 필터링\n",
    "    filtered_movies = filter_movies_by_history(top_movies, extract_previous_movie_ids(purchase_history))\n",
    "\n",
    "    # 🔹 정답 추출 (영화 ID만)\n",
    "    answer = df_test.iloc[idx].movie_explain\n",
    "    answer_id = re.search(r\"(\\d+)\", answer).group(1)\n",
    "\n",
    "    # 🔹 추천 영화 리스트에서 영화 ID만 추출\n",
    "    filtered_movie_ids = [re.search(r\"(\\d+)\", movie).group(1) for movie, _ in filtered_movies]\n",
    "\n",
    "    # 🔹 Hit 여부 확인\n",
    "    hit = 1 if answer_id in filtered_movie_ids else 0\n",
    "\n",
    "    # 결과 DataFrame에 기록\n",
    "    results = pd.concat([results, pd.DataFrame({\n",
    "        \"UserId\": [target_user_id],\n",
    "        \"Hit\": [hit],\n",
    "        \"Answer\": [answer_id],\n",
    "        \"Recommended\": [\", \".join(filtered_movie_ids)]\n",
    "    })], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('rapor_res.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hit\n",
       "0    0.924669\n",
       "1    0.075331\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.Hit.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.075"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 휴리스틱 - 수정할 수 있는 변수들 \n",
    "- raptor 파라미터 : threshold, \n",
    "- faiss 검색 범위 k \n",
    "- window 확장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:14<00:00,  6.15s/it]\n",
      "/tmp/ipykernel_1431090/578930027.py:99: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, results], ignore_index=True)\n",
      "100%|██████████| 100/100 [10:02<00:00,  6.02s/it]\n",
      "100%|██████████| 100/100 [10:04<00:00,  6.04s/it]\n",
      "100%|██████████| 100/100 [10:04<00:00,  6.04s/it]\n",
      "100%|██████████| 100/100 [10:09<00:00,  6.09s/it]\n",
      "100%|██████████| 100/100 [10:07<00:00,  6.08s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm \n",
    "# (1) 실험할 파라미터 목록 정의\n",
    "threshold_values = [0.005]\n",
    "faiss_k_values = [700,850,1000]\n",
    "window_values = [1, 2]\n",
    "\n",
    "# 전체 결과를 저장할 DataFrame (파라미터 + 결과)\n",
    "all_results = pd.DataFrame(columns=[\"UserId\", \"Hit\", \"Answer\", \"Recommended\",\n",
    "                                    \"threshold\", \"faiss_k\", \"window\"])\n",
    "\n",
    "# (2) 파라미터 조합으로 반복 실험\n",
    "for threshold in threshold_values:\n",
    "    for k_val in faiss_k_values:\n",
    "        for window_size in window_values:\n",
    "            # 각 파라미터 세팅마다 100명(예시) 유저 실행\n",
    "            results = pd.DataFrame(columns=[\"UserId\", \"Hit\", \"Answer\", \"Recommended\"])\n",
    "\n",
    "            for idx in tqdm(range(100)):\n",
    "                target_user_id = str(idx + 1)  # 유저 ID는 1부터 시작\n",
    "                target_user_text = df.loc[df.UserId == int(target_user_id), 'chunk_header'].iloc[0]\n",
    "\n",
    "                # (2-1) Raptor Tree 검색 (threshold 설정)\n",
    "                best_cluster_id, similar_users = raptor_tree.search_user_cluster(\n",
    "                    target_user_id, \n",
    "                    target_user_text, \n",
    "                    threshold=threshold   # 🔥 threshold 변경\n",
    "                )\n",
    "\n",
    "                # 최신 구매 기록\n",
    "                purchase_history = data.iloc[idx]['movie_explain']\n",
    "                query = \" \".join(purchase_history[-1:])\n",
    "\n",
    "                # (2-2) FAISS 검색 (k 값 변경)\n",
    "                # retriever 설정 시 search_kwargs에 k_val 대입\n",
    "                retriever_k = vectorstore.as_retriever(\n",
    "                    search_kwargs={\"k\": k_val}  # 🔥 k값 변경\n",
    "                )\n",
    "                records = retriever_k.get_relevant_documents(query)\n",
    "\n",
    "                record_user_ids = [str(record.metadata['UserId']) for record in records]\n",
    "                intersection = set(map(str, similar_users)).intersection(set(record_user_ids))\n",
    "\n",
    "                # 'similar_users'에 속하는 유저만 필터링\n",
    "                filtered_records = [\n",
    "                    record for record in records\n",
    "                    if str(record.metadata['UserId']) in intersection\n",
    "                ]\n",
    "\n",
    "                # (2-3) 메타 청크 앞뒤 청크 추출 (window_size로 변경)\n",
    "                context_results = get_documents_with_context(\n",
    "                    vectorstore, \n",
    "                    filtered_records, \n",
    "                    context_window=window_size  # 🔥 window 변경\n",
    "                )\n",
    "\n",
    "                flattened_results = [doc for sublist in context_results for doc in sublist]\n",
    "\n",
    "                # 사용자별 영화 ID 가져오기\n",
    "                user_movies = get_user_movies(flattened_results)\n",
    "\n",
    "                # 사용자-영화 그래프 생성\n",
    "                G = create_user_movie_graph(user_movies)\n",
    "\n",
    "                # Top-10 영화 리스트 가져오기\n",
    "                top_movies = get_top_10_common_movies(G)\n",
    "\n",
    "                # 이전 기록에 포함되지 않은 영화만 필터링\n",
    "                filtered_movies = filter_movies_by_history(\n",
    "                    top_movies, \n",
    "                    extract_previous_movie_ids(purchase_history)\n",
    "                )\n",
    "\n",
    "                # 🔹 정답 추출 (영화 ID만)\n",
    "                answer = df_test.iloc[idx].movie_explain\n",
    "                answer_id = re.search(r\"(\\d+)\", answer).group(1)\n",
    "\n",
    "                # 🔹 추천 영화 리스트에서 영화 ID만 추출\n",
    "                filtered_movie_ids = [re.search(r\"(\\d+)\", movie).group(1) for movie, _ in filtered_movies]\n",
    "\n",
    "                # 🔹 Hit 여부 확인\n",
    "                hit = 1 if answer_id in filtered_movie_ids else 0\n",
    "\n",
    "                # 결과 DataFrame에 기록 (이번 파라미터 세팅용)\n",
    "                results = pd.concat([results, pd.DataFrame({\n",
    "                    \"UserId\": [target_user_id],\n",
    "                    \"Hit\": [hit],\n",
    "                    \"Answer\": [answer_id],\n",
    "                    \"Recommended\": [\", \".join(filtered_movie_ids)]\n",
    "                })], ignore_index=True)\n",
    "\n",
    "            # (3) 이번 파라미터 세팅의 결과를 all_results에 병합\n",
    "            # 파라미터 컬럼 추가\n",
    "            results[\"threshold\"] = threshold\n",
    "            results[\"faiss_k\"] = k_val\n",
    "            results[\"window\"] = window_size\n",
    "\n",
    "            all_results = pd.concat([all_results, results], ignore_index=True)\n",
    "\n",
    "# (4) all_results를 분석하여 파라미터별 성능 비교\n",
    "# 예: 파라미터별 Hit Rate 계산\n",
    "grouped = all_results.groupby([\"threshold\", \"faiss_k\", \"window\"])\n",
    "performance = grouped[\"Hit\"].mean().reset_index(name=\"HitRate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>faiss_k</th>\n",
       "      <th>window</th>\n",
       "      <th>HitRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005</td>\n",
       "      <td>700</td>\n",
       "      <td>2</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005</td>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005</td>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  faiss_k  window HitRate\n",
       "0      0.005      700       1    0.13\n",
       "1      0.005      700       2    0.14\n",
       "2      0.005      850       1    0.15\n",
       "3      0.005      850       2    0.14\n",
       "4      0.005     1000       1    0.12\n",
       "5      0.005     1000       2    0.12"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance.to_csv('perform_100_thresholds_faiss_k_window_size.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "# (1) 실험할 파라미터 목록 정의\n",
    "threshold_values = [0.005]\n",
    "faiss_k_values = [800,850,900]\n",
    "window_values = [2,3]\n",
    "\n",
    "# 전체 결과를 저장할 DataFrame (파라미터 + 결과)\n",
    "all_results = pd.DataFrame(columns=[\"UserId\", \"Hit\", \"Answer\", \"Recommended\",\n",
    "                                    \"threshold\", \"faiss_k\", \"window\"])\n",
    "\n",
    "# (2) 파라미터 조합으로 반복 실험\n",
    "for threshold in threshold_values:\n",
    "    for k_val in faiss_k_values:\n",
    "        for window_size in window_values:\n",
    "            # 각 파라미터 세팅마다 100명(예시) 유저 실행\n",
    "            results = pd.DataFrame(columns=[\"UserId\", \"Hit\", \"Answer\", \"Recommended\"])\n",
    "\n",
    "            for idx in tqdm(range(300)):\n",
    "                target_user_id = str(idx + 1)  # 유저 ID는 1부터 시작\n",
    "                target_user_text = df.loc[df.UserId == int(target_user_id), 'chunk_header'].iloc[0]\n",
    "\n",
    "                # (2-1) Raptor Tree 검색 (threshold 설정)\n",
    "                best_cluster_id, similar_users = raptor_tree.search_user_cluster(\n",
    "                    target_user_id, \n",
    "                    target_user_text, \n",
    "                    threshold=threshold   # 🔥 threshold 변경\n",
    "                )\n",
    "\n",
    "                # 최신 구매 기록\n",
    "                purchase_history = data.iloc[idx]['movie_explain']\n",
    "                query = \" \".join(purchase_history[-1:])\n",
    "\n",
    "                # (2-2) FAISS 검색 (k 값 변경)\n",
    "                # retriever 설정 시 search_kwargs에 k_val 대입\n",
    "                retriever_k = vectorstore.as_retriever(\n",
    "                    search_kwargs={\"k\": k_val}  # 🔥 k값 변경\n",
    "                )\n",
    "                records = retriever_k.get_relevant_documents(query)\n",
    "\n",
    "                record_user_ids = [str(record.metadata['UserId']) for record in records]\n",
    "                intersection = set(map(str, similar_users)).intersection(set(record_user_ids))\n",
    "\n",
    "                # 'similar_users'에 속하는 유저만 필터링\n",
    "                filtered_records = [\n",
    "                    record for record in records\n",
    "                    if str(record.metadata['UserId']) in intersection\n",
    "                ]\n",
    "\n",
    "                # (2-3) 메타 청크 앞뒤 청크 추출 (window_size로 변경)\n",
    "                context_results = get_documents_with_context(\n",
    "                    vectorstore, \n",
    "                    filtered_records, \n",
    "                    context_window=window_size  # 🔥 window 변경\n",
    "                )\n",
    "\n",
    "                flattened_results = [doc for sublist in context_results for doc in sublist]\n",
    "\n",
    "                # 사용자별 영화 ID 가져오기\n",
    "                user_movies = get_user_movies(flattened_results)\n",
    "\n",
    "                # 사용자-영화 그래프 생성\n",
    "                G = create_user_movie_graph(user_movies)\n",
    "\n",
    "                # Top-10 영화 리스트 가져오기\n",
    "                top_movies = get_top_10_common_movies(G)\n",
    "\n",
    "                # 이전 기록에 포함되지 않은 영화만 필터링\n",
    "                filtered_movies = filter_movies_by_history(\n",
    "                    top_movies, \n",
    "                    extract_previous_movie_ids(purchase_history)\n",
    "                )\n",
    "\n",
    "                # 🔹 정답 추출 (영화 ID만)\n",
    "                answer = df_test.iloc[idx].movie_explain\n",
    "                answer_id = re.search(r\"(\\d+)\", answer).group(1)\n",
    "\n",
    "                # 🔹 추천 영화 리스트에서 영화 ID만 추출\n",
    "                filtered_movie_ids = [re.search(r\"(\\d+)\", movie).group(1) for movie, _ in filtered_movies]\n",
    "\n",
    "                # 🔹 Hit 여부 확인\n",
    "                hit = 1 if answer_id in filtered_movie_ids else 0\n",
    "\n",
    "                # 결과 DataFrame에 기록 (이번 파라미터 세팅용)\n",
    "                results = pd.concat([results, pd.DataFrame({\n",
    "                    \"UserId\": [target_user_id],\n",
    "                    \"Hit\": [hit],\n",
    "                    \"Answer\": [answer_id],\n",
    "                    \"Recommended\": [\", \".join(filtered_movie_ids)]\n",
    "                })], ignore_index=True)\n",
    "\n",
    "            # (3) 이번 파라미터 세팅의 결과를 all_results에 병합\n",
    "            # 파라미터 컬럼 추가\n",
    "            results[\"threshold\"] = threshold\n",
    "            results[\"faiss_k\"] = k_val\n",
    "            results[\"window\"] = window_size\n",
    "\n",
    "            all_results = pd.concat([all_results, results], ignore_index=True)\n",
    "\n",
    "# (4) all_results를 분석하여 파라미터별 성능 비교\n",
    "# 예: 파라미터별 Hit Rate 계산\n",
    "grouped = all_results.groupby([\"threshold\", \"faiss_k\", \"window\"])\n",
    "performance = grouped[\"Hit\"].mean().reset_index(name=\"HitRate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [31:40<00:00,  6.33s/it]\n",
      "/tmp/ipykernel_1438256/1277201905.py:98: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, results], ignore_index=True)\n",
      "100%|██████████| 300/300 [33:42<00:00,  6.74s/it]\n",
      "100%|██████████| 300/300 [37:45<00:00,  7.55s/it]\n",
      "100%|██████████| 300/300 [37:14<00:00,  7.45s/it]\n",
      "100%|██████████| 300/300 [37:40<00:00,  7.54s/it]\n",
      "100%|██████████| 300/300 [37:32<00:00,  7.51s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# (1) 실험할 파라미터 목록 정의\n",
    "threshold_values = [0.005]\n",
    "faiss_k_values = [800,850,900]\n",
    "window_values = [2,3]\n",
    "\n",
    "# 전체 결과를 저장할 DataFrame (파라미터 + 결과)\n",
    "all_results = pd.DataFrame(columns=[\"UserId\", \"Hit\", \"Answer\", \"Recommended\",\n",
    "                                    \"threshold\", \"faiss_k\", \"window\"])\n",
    "\n",
    "# (2) 파라미터 조합으로 반복 실험\n",
    "for threshold in threshold_values:\n",
    "    for k_val in faiss_k_values:\n",
    "        for window_size in window_values:\n",
    "            # 각 파라미터 세팅마다 100명(예시) 유저 실행\n",
    "            results = pd.DataFrame(columns=[\"UserId\", \"Hit\", \"Answer\", \"Recommended\"])\n",
    "\n",
    "            for idx in tqdm(range(300)):\n",
    "                target_user_id = str(idx + 1)  # 유저 ID는 1부터 시작\n",
    "                target_user_text = df.loc[df.UserId == int(target_user_id), 'chunk_header'].iloc[0]\n",
    "\n",
    "                # (2-1) Raptor Tree 검색 (threshold 설정)\n",
    "                best_cluster_id, similar_users = raptor_tree.search_user_cluster(\n",
    "                    target_user_id, \n",
    "                    target_user_text, \n",
    "                    threshold=threshold   # 🔥 threshold 변경\n",
    "                )\n",
    "\n",
    "                # 최신 구매 기록\n",
    "                purchase_history = data.iloc[idx]['movie_explain']\n",
    "                query = \" \".join(purchase_history[-1:])\n",
    "\n",
    "                # (2-2) FAISS 검색 (k 값 변경)\n",
    "                # retriever 설정 시 search_kwargs에 k_val 대입\n",
    "                retriever_k = vectorstore.as_retriever(\n",
    "                    search_kwargs={\"k\": k_val}  # 🔥 k값 변경\n",
    "                )\n",
    "                records = retriever_k.get_relevant_documents(query)\n",
    "\n",
    "                record_user_ids = [str(record.metadata['UserId']) for record in records]\n",
    "                intersection = set(map(str, similar_users)).intersection(set(record_user_ids))\n",
    "\n",
    "                # 'similar_users'에 속하는 유저만 필터링\n",
    "                filtered_records = [\n",
    "                    record for record in records\n",
    "                    if str(record.metadata['UserId']) in intersection\n",
    "                ]\n",
    "\n",
    "                # (2-3) 메타 청크 앞뒤 청크 추출 (window_size로 변경)\n",
    "                context_results = get_documents_with_context(\n",
    "                    vectorstore, \n",
    "                    filtered_records, \n",
    "                    context_window=window_size  # 🔥 window 변경\n",
    "                )\n",
    "\n",
    "                flattened_results = [doc for sublist in context_results for doc in sublist]\n",
    "\n",
    "                # 사용자별 영화 ID 가져오기\n",
    "                user_movies = get_user_movies(flattened_results)\n",
    "\n",
    "                # 사용자-영화 그래프 생성\n",
    "                G = create_user_movie_graph(user_movies)\n",
    "\n",
    "                # Top-10 영화 리스트 가져오기\n",
    "                top_movies = get_top_10_common_movies(G)\n",
    "\n",
    "                # 이전 기록에 포함되지 않은 영화만 필터링\n",
    "                filtered_movies = filter_movies_by_history(\n",
    "                    top_movies, \n",
    "                    extract_previous_movie_ids(purchase_history)\n",
    "                )\n",
    "\n",
    "                # 🔹 정답 추출 (영화 ID만)\n",
    "                answer = df_test.iloc[idx].movie_explain\n",
    "                answer_id = re.search(r\"(\\d+)\", answer).group(1)\n",
    "\n",
    "                # 🔹 추천 영화 리스트에서 영화 ID만 추출\n",
    "                filtered_movie_ids = [re.search(r\"(\\d+)\", movie).group(1) for movie, _ in filtered_movies]\n",
    "\n",
    "                # 🔹 Hit 여부 확인\n",
    "                hit = 1 if answer_id in filtered_movie_ids else 0\n",
    "\n",
    "                # 결과 DataFrame에 기록 (이번 파라미터 세팅용)\n",
    "                results = pd.concat([results, pd.DataFrame({\n",
    "                    \"UserId\": [target_user_id],\n",
    "                    \"Hit\": [hit],\n",
    "                    \"Answer\": [answer_id],\n",
    "                    \"Recommended\": [\", \".join(filtered_movie_ids)]\n",
    "                })], ignore_index=True)\n",
    "\n",
    "            # (3) 이번 파라미터 세팅의 결과를 all_results에 병합\n",
    "            # 파라미터 컬럼 추가\n",
    "            results[\"threshold\"] = threshold\n",
    "            results[\"faiss_k\"] = k_val\n",
    "            results[\"window\"] = window_size\n",
    "\n",
    "            all_results = pd.concat([all_results, results], ignore_index=True)\n",
    "\n",
    "# (4) all_results를 분석하여 파라미터별 성능 비교\n",
    "# 예: 파라미터별 Hit Rate 계산\n",
    "grouped = all_results.groupby([\"threshold\", \"faiss_k\", \"window\"])\n",
    "performance = grouped[\"Hit\"].mean().reset_index(name=\"HitRate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>faiss_k</th>\n",
       "      <th>window</th>\n",
       "      <th>HitRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>800</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005</td>\n",
       "      <td>800</td>\n",
       "      <td>3</td>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005</td>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005</td>\n",
       "      <td>850</td>\n",
       "      <td>3</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005</td>\n",
       "      <td>900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.123333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005</td>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  faiss_k  window   HitRate\n",
       "0      0.005      800       2  0.133333\n",
       "1      0.005      800       3  0.116667\n",
       "2      0.005      850       2  0.133333\n",
       "3      0.005      850       3      0.11\n",
       "4      0.005      900       2  0.123333\n",
       "5      0.005      900       3      0.11"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [09:00<00:00,  5.40s/it]\n",
      "/tmp/ipykernel_1438256/2301780778.py:98: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_results = pd.concat([all_results, results], ignore_index=True)\n",
      "100%|██████████| 100/100 [08:58<00:00,  5.38s/it]\n",
      "100%|██████████| 100/100 [09:04<00:00,  5.44s/it]\n",
      "100%|██████████| 100/100 [09:09<00:00,  5.50s/it]\n",
      "100%|██████████| 100/100 [09:20<00:00,  5.61s/it]\n",
      "100%|██████████| 100/100 [09:20<00:00,  5.61s/it]\n",
      "100%|██████████| 100/100 [09:21<00:00,  5.62s/it]\n",
      "100%|██████████| 100/100 [09:07<00:00,  5.48s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# (1) 실험할 파라미터 목록 정의\n",
    "threshold_values = [0.003, 0.004]\n",
    "faiss_k_values = [600, 750]\n",
    "window_values = [1,2]\n",
    "\n",
    "# 전체 결과를 저장할 DataFrame (파라미터 + 결과)\n",
    "all_results = pd.DataFrame(columns=[\"UserId\", \"Hit\", \"Answer\", \"Recommended\",\n",
    "                                    \"threshold\", \"faiss_k\", \"window\"])\n",
    "\n",
    "# (2) 파라미터 조합으로 반복 실험\n",
    "for threshold in threshold_values:\n",
    "    for k_val in faiss_k_values:\n",
    "        for window_size in window_values:\n",
    "            # 각 파라미터 세팅마다 100명(예시) 유저 실행\n",
    "            results = pd.DataFrame(columns=[\"UserId\", \"Hit\", \"Answer\", \"Recommended\"])\n",
    "\n",
    "            for idx in tqdm(range(100)):\n",
    "                target_user_id = str(idx + 1)  # 유저 ID는 1부터 시작\n",
    "                target_user_text = df.loc[df.UserId == int(target_user_id), 'chunk_header'].iloc[0]\n",
    "\n",
    "                # (2-1) Raptor Tree 검색 (threshold 설정)\n",
    "                best_cluster_id, similar_users = raptor_tree.search_user_cluster(\n",
    "                    target_user_id, \n",
    "                    target_user_text, \n",
    "                    threshold=threshold   # 🔥 threshold 변경\n",
    "                )\n",
    "\n",
    "                # 최신 구매 기록\n",
    "                purchase_history = data.iloc[idx]['movie_explain']\n",
    "                query = \" \".join(purchase_history[-1:])\n",
    "\n",
    "                # (2-2) FAISS 검색 (k 값 변경)\n",
    "                # retriever 설정 시 search_kwargs에 k_val 대입\n",
    "                retriever_k = vectorstore.as_retriever(\n",
    "                    search_kwargs={\"k\": k_val}  # 🔥 k값 변경\n",
    "                )\n",
    "                records = retriever_k.get_relevant_documents(query)\n",
    "\n",
    "                record_user_ids = [str(record.metadata['UserId']) for record in records]\n",
    "                intersection = set(map(str, similar_users)).intersection(set(record_user_ids))\n",
    "\n",
    "                # 'similar_users'에 속하는 유저만 필터링\n",
    "                filtered_records = [\n",
    "                    record for record in records\n",
    "                    if str(record.metadata['UserId']) in intersection\n",
    "                ]\n",
    "\n",
    "                # (2-3) 메타 청크 앞뒤 청크 추출 (window_size로 변경)\n",
    "                context_results = get_documents_with_context(\n",
    "                    vectorstore, \n",
    "                    filtered_records, \n",
    "                    context_window=window_size  # 🔥 window 변경\n",
    "                )\n",
    "\n",
    "                flattened_results = [doc for sublist in context_results for doc in sublist]\n",
    "\n",
    "                # 사용자별 영화 ID 가져오기\n",
    "                user_movies = get_user_movies(flattened_results)\n",
    "\n",
    "                # 사용자-영화 그래프 생성\n",
    "                G = create_user_movie_graph(user_movies)\n",
    "\n",
    "                # Top-10 영화 리스트 가져오기\n",
    "                top_movies = get_top_10_common_movies(G)\n",
    "\n",
    "                # 이전 기록에 포함되지 않은 영화만 필터링\n",
    "                filtered_movies = filter_movies_by_history(\n",
    "                    top_movies, \n",
    "                    extract_previous_movie_ids(purchase_history)\n",
    "                )\n",
    "\n",
    "                # 🔹 정답 추출 (영화 ID만)\n",
    "                answer = df_test.iloc[idx].movie_explain\n",
    "                answer_id = re.search(r\"(\\d+)\", answer).group(1)\n",
    "\n",
    "                # 🔹 추천 영화 리스트에서 영화 ID만 추출\n",
    "                filtered_movie_ids = [re.search(r\"(\\d+)\", movie).group(1) for movie, _ in filtered_movies]\n",
    "\n",
    "                # 🔹 Hit 여부 확인\n",
    "                hit = 1 if answer_id in filtered_movie_ids else 0\n",
    "\n",
    "                # 결과 DataFrame에 기록 (이번 파라미터 세팅용)\n",
    "                results = pd.concat([results, pd.DataFrame({\n",
    "                    \"UserId\": [target_user_id],\n",
    "                    \"Hit\": [hit],\n",
    "                    \"Answer\": [answer_id],\n",
    "                    \"Recommended\": [\", \".join(filtered_movie_ids)]\n",
    "                })], ignore_index=True)\n",
    "\n",
    "            # (3) 이번 파라미터 세팅의 결과를 all_results에 병합\n",
    "            # 파라미터 컬럼 추가\n",
    "            results[\"threshold\"] = threshold\n",
    "            results[\"faiss_k\"] = k_val\n",
    "            results[\"window\"] = window_size\n",
    "\n",
    "            all_results = pd.concat([all_results, results], ignore_index=True)\n",
    "\n",
    "# (4) all_results를 분석하여 파라미터별 성능 비교\n",
    "# 예: 파라미터별 Hit Rate 계산\n",
    "grouped = all_results.groupby([\"threshold\", \"faiss_k\", \"window\"])\n",
    "performance = grouped[\"Hit\"].mean().reset_index(name=\"HitRate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>faiss_k</th>\n",
       "      <th>window</th>\n",
       "      <th>HitRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003</td>\n",
       "      <td>600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003</td>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003</td>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004</td>\n",
       "      <td>600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004</td>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004</td>\n",
       "      <td>750</td>\n",
       "      <td>2</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  faiss_k  window HitRate\n",
       "0      0.003      600       1    0.14\n",
       "1      0.003      600       2    0.13\n",
       "2      0.003      750       1    0.15\n",
       "3      0.003      750       2    0.14\n",
       "4      0.004      600       1    0.14\n",
       "5      0.004      600       2    0.13\n",
       "6      0.004      750       1    0.15\n",
       "7      0.004      750       2    0.14"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2553348102.py, line 103)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[34], line 103\u001b[0;36m\u001b[0m\n\u001b[0;31m    performance = grouped[\"Hit\"].mean().reset_index(name=\"HitRate\")rom tqdm import tqdm\u001b[0m\n\u001b[0m                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# (1) 실험할 파라미터 목록 정의\n",
    "threshold_values = [0.003, 0.004]\n",
    "faiss_k_values = [600, 750]\n",
    "window_values = [1,2]\n",
    "\n",
    "# 전체 결과를 저장할 DataFrame (파라미터 + 결과)\n",
    "all_results = pd.DataFrame(columns=[\"UserId\", \"Hit\", \"Answer\", \"Recommended\",\n",
    "                                    \"threshold\", \"faiss_k\", \"window\"])\n",
    "\n",
    "# (2) 파라미터 조합으로 반복 실험\n",
    "for threshold in threshold_values:\n",
    "    for k_val in faiss_k_values:\n",
    "        for window_size in window_values:\n",
    "            # 각 파라미터 세팅마다 100명(예시) 유저 실행\n",
    "            results = pd.DataFrame(columns=[\"UserId\", \"Hit\", \"Answer\", \"Recommended\"])\n",
    "\n",
    "            for idx in tqdm(range(100)):\n",
    "                target_user_id = str(idx + 1)  # 유저 ID는 1부터 시작\n",
    "                target_user_text = df.loc[df.UserId == int(target_user_id), 'chunk_header'].iloc[0]\n",
    "\n",
    "                # (2-1) Raptor Tree 검색 (threshold 설정)\n",
    "                best_cluster_id, similar_users = raptor_tree.search_user_cluster(\n",
    "                    target_user_id, \n",
    "                    target_user_text, \n",
    "                    threshold=threshold   # 🔥 threshold 변경\n",
    "                )\n",
    "\n",
    "                # 최신 구매 기록\n",
    "                purchase_history = data.iloc[idx]['movie_explain']\n",
    "                query = \" \".join(purchase_history[-1:])\n",
    "\n",
    "                # (2-2) FAISS 검색 (k 값 변경)\n",
    "                # retriever 설정 시 search_kwargs에 k_val 대입\n",
    "                retriever_k = vectorstore.as_retriever(\n",
    "                    search_kwargs={\"k\": k_val}  # 🔥 k값 변경\n",
    "                )\n",
    "                records = retriever_k.get_relevant_documents(query)\n",
    "\n",
    "                record_user_ids = [str(record.metadata['UserId']) for record in records]\n",
    "                intersection = set(map(str, similar_users)).intersection(set(record_user_ids))\n",
    "\n",
    "                # 'similar_users'에 속하는 유저만 필터링\n",
    "                filtered_records = [\n",
    "                    record for record in records\n",
    "                    if str(record.metadata['UserId']) in intersection\n",
    "                ]\n",
    "\n",
    "                # (2-3) 메타 청크 앞뒤 청크 추출 (window_size로 변경)\n",
    "                context_results = get_documents_with_context(\n",
    "                    vectorstore, \n",
    "                    filtered_records, \n",
    "                    context_window=window_size  # 🔥 window 변경\n",
    "                )\n",
    "\n",
    "                flattened_results = [doc for sublist in context_results for doc in sublist]\n",
    "\n",
    "                # 사용자별 영화 ID 가져오기\n",
    "                user_movies = get_user_movies(flattened_results)\n",
    "\n",
    "                # 사용자-영화 그래프 생성\n",
    "                G = create_user_movie_graph(user_movies)\n",
    "\n",
    "                # Top-10 영화 리스트 가져오기\n",
    "                top_movies = get_top_10_common_movies(G)\n",
    "\n",
    "                # 이전 기록에 포함되지 않은 영화만 필터링\n",
    "                filtered_movies = filter_movies_by_history(\n",
    "                    top_movies, \n",
    "                    extract_previous_movie_ids(purchase_history)\n",
    "                )\n",
    "\n",
    "                # 🔹 정답 추출 (영화 ID만)\n",
    "                answer = df_test.iloc[idx].movie_explain\n",
    "                answer_id = re.search(r\"(\\d+)\", answer).group(1)\n",
    "\n",
    "                # 🔹 추천 영화 리스트에서 영화 ID만 추출\n",
    "                filtered_movie_ids = [re.search(r\"(\\d+)\", movie).group(1) for movie, _ in filtered_movies]\n",
    "\n",
    "                # 🔹 Hit 여부 확인\n",
    "                hit = 1 if answer_id in filtered_movie_ids else 0\n",
    "\n",
    "                # 결과 DataFrame에 기록 (이번 파라미터 세팅용)\n",
    "                results = pd.concat([results, pd.DataFrame({\n",
    "                    \"UserId\": [target_user_id],\n",
    "                    \"Hit\": [hit],\n",
    "                    \"Answer\": [answer_id],\n",
    "                    \"Recommended\": [\", \".join(filtered_movie_ids)]\n",
    "                })], ignore_index=True)\n",
    "\n",
    "            # (3) 이번 파라미터 세팅의 결과를 all_results에 병합\n",
    "            # 파라미터 컬럼 추가\n",
    "            results[\"threshold\"] = threshold\n",
    "            results[\"faiss_k\"] = k_val\n",
    "            results[\"window\"] = window_size\n",
    "\n",
    "            all_results = pd.concat([all_results, results], ignore_index=True)\n",
    "\n",
    "# (4) all_results를 분석하여 파라미터별 성능 비교\n",
    "# 예: 파라미터별 Hit Rate 계산\n",
    "grouped = all_results.groupby([\"threshold\", \"faiss_k\", \"window\"])\n",
    "performance = grouped[\"Hit\"].mean().reset_index(name=\"HitRate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 26/500 [02:25<44:16,  5.60s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m target_user_text \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df\u001b[38;5;241m.\u001b[39mUserId \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mint\u001b[39m(target_user_id), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunk_header\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# (2-1) Raptor Tree 검색 (threshold 설정)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m best_cluster_id, similar_users \u001b[38;5;241m=\u001b[39m \u001b[43mraptor_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_user_cluster\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_user_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_user_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# 🔥 threshold 변경\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 최신 구매 기록\u001b[39;00m\n\u001b[1;32m     28\u001b[0m purchase_history \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_explain\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[7], line 101\u001b[0m, in \u001b[0;36mRaptorTree.search_user_cluster\u001b[0;34m(self, target_user_id, target_user_text, threshold)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m texts_to_embed:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m embeddings_cluster \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts_to_embed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m mean_embedding \u001b[38;5;241m=\u001b[39m embeddings_cluster\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    104\u001b[0m clusters_filtered\u001b[38;5;241m.\u001b[39mappend(cluster)\n",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m, in \u001b[0;36mEmbeddingGenerator.embed_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membed_texts\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# 텍스트 리스트를 임베딩 벡터로 변환하여 반환\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:623\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 623\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    625\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:690\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m    689\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:442\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m trans_features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    437\u001b[0m     key: value\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    440\u001b[0m }\n\u001b[0;32m--> 442\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# If the AutoModel is wrapped with a PeftModelForFeatureExtraction, then it may have added virtual tokens\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# We need to extend the attention mask to include these virtual tokens, or the pooling will fail\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:524\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    516\u001b[0m         hidden_states,\n\u001b[1;32m    517\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m         output_attentions,\n\u001b[1;32m    523\u001b[0m     )\n\u001b[0;32m--> 524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:468\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    466\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    467\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 468\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1735\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1732\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1736\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1737\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# (1) 실험 파라미터 (고정값)\n",
    "threshold = 0.003\n",
    "k_val = 750\n",
    "window_size = 1\n",
    "\n",
    "# 결과 저장용 DataFrame\n",
    "all_results = pd.DataFrame(columns=[\"UserId\", \"Hit\", \"Answer\", \"Recommended\",\n",
    "                                    \"threshold\", \"faiss_k\", \"window\"])\n",
    "\n",
    "# (2) 유저 단일 세팅 실험 (예: 5명 유저 반복)\n",
    "for idx in tqdm(range(5)):\n",
    "    results = pd.DataFrame(columns=[\"UserId\", \"Hit\", \"Answer\", \"Recommended\"])\n",
    "\n",
    "    target_user_id = str(idx + 1)  # 유저 ID는 1부터 시작\n",
    "    target_user_text = df.loc[df.UserId == int(target_user_id), 'chunk_header'].iloc[0]\n",
    "\n",
    "    # (2-1) Raptor Tree 검색\n",
    "    best_cluster_id, similar_users = raptor_tree.search_user_cluster(\n",
    "        target_user_id,\n",
    "        target_user_text,\n",
    "        threshold=threshold\n",
    "    )\n",
    "\n",
    "    # 최신 구매 기록에서 마지막 항목을 질의로 사용\n",
    "    purchase_history = data.iloc[idx]['movie_explain']\n",
    "    query = \" \".join(purchase_history[-1:])\n",
    "\n",
    "    # (2-2) FAISS 검색\n",
    "    retriever_k = vectorstore.as_retriever(\n",
    "        search_kwargs={\"k\": k_val}\n",
    "    )\n",
    "    records = retriever_k.get_relevant_documents(query)\n",
    "\n",
    "    record_user_ids = [str(record.metadata['UserId']) for record in records]\n",
    "    intersection = set(map(str, similar_users)).intersection(set(record_user_ids))\n",
    "\n",
    "    filtered_records = [\n",
    "        record for record in records\n",
    "        if str(record.metadata['UserId']) in intersection\n",
    "    ]\n",
    "\n",
    "    # (2-3) 문맥 확장 (window size 적용)\n",
    "    context_results = get_documents_with_context(\n",
    "        vectorstore,\n",
    "        filtered_records,\n",
    "        context_window=window_size\n",
    "    )\n",
    "    flattened_results = [doc for sublist in context_results for doc in sublist]\n",
    "\n",
    "    # 유저-영화 그래프 생성 및 추천 영화 추출\n",
    "    user_movies = get_user_movies(flattened_results)\n",
    "    G = create_user_movie_graph(user_movies)\n",
    "    top_movies = get_top_10_common_movies(G)\n",
    "\n",
    "    # 과거 기록 제거\n",
    "    filtered_movies = filter_movies_by_history(\n",
    "        top_movies,\n",
    "        extract_previous_movie_ids(purchase_history)\n",
    "    )\n",
    "\n",
    "    # 정답 및 예측 결과 비교\n",
    "    answer = df_test.iloc[idx].movie_explain\n",
    "    match = re.search(r\"(\\d+)\", answer)\n",
    "    answer_id = match.group(1) if match else None\n",
    "\n",
    "    filtered_movie_ids = [\n",
    "        re.search(r\"(\\d+)\", movie).group(1)\n",
    "        for movie, _ in filtered_movies\n",
    "        if re.search(r\"(\\d+)\", movie)\n",
    "    ]\n",
    "\n",
    "    hit = 1 if answer_id in filtered_movie_ids else 0\n",
    "\n",
    "    # 유저별 결과 저장\n",
    "    results = pd.concat([results, pd.DataFrame({\n",
    "        \"UserId\": [target_user_id],\n",
    "        \"Hit\": [hit],\n",
    "        \"Answer\": [answer_id],\n",
    "        \"Recommended\": [\", \".join(filtered_movie_ids)]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    # 파라미터 정보 추가\n",
    "    results[\"threshold\"] = threshold\n",
    "    results[\"faiss_k\"] = k_val\n",
    "    results[\"window\"] = window_size\n",
    "\n",
    "    all_results = pd.concat([all_results, results], ignore_index=True)\n",
    "\n",
    "# (3) 최종 성능 평가\n",
    "performance = all_results[\"Hit\"].mean()\n",
    "print(f\"Hit Rate: {performance:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
